import re
import io
import requests
from bs4 import BeautifulSoup
from PIL import Image
from zipfile import ZipFile
from dataclasses import dataclass
from argparse import ArgumentParser
from pathlib import Path


@dataclass
class Img:
    filename: str
    url: str

    def __post_init__(self):
        if (m := re.search(r"(\d+)", self.filename)) is None:
            raise ValueError("No number in id")
        self.filename = f"{int(m.group(0)) + 1:03}.jpg"
        self.url = self.url.strip()

    def download_jpeg(self) -> bytes:
        r = requests.get(self.url, stream=True)
        image = Image.open(io.BytesIO(r.content))
        buffer = io.BytesIO()
        image.save(buffer, format="jpeg")
        return buffer.getvalue()


@dataclass
class Archive:
    filename: str
    imgs: [Img]

    def save(self, directory: Path):
        with ZipFile(directory / self.filename, "w") as archive:
            for img in self.imgs:
                archive.writestr(img.filename, img.download_jpeg())


def find_images(url: str) -> [Img]:
    soup = BeautifulSoup(requests.get(url).text, "html.parser")
    images = soup.find_all("img")
    return [Img(image.get("id"), image.get("data-src")) for image in images]


def main():
    parser = ArgumentParser(
        prog="ComicDownloader",
        description="Given an URL to a website with images, download and create cbz file from them.",
    )

    parser.add_argument("URLs", nargs='+', help="urls with images to download")
    parser.add_argument(
        "-o",
        "--output",
        nargs="?",
        help="name of output file, could only be specified with url (default: filename in url)",
    )
    parser.add_argument(
        "-d",
        "--directory",
        nargs="?",
        default=".",
        type=Path,
        help="directory to put output file into (default: .)",
    )

    args = parser.parse_args()

    match (args.URLs, args.output):
        case (_, None):
            output = [f"{Path(url).name}.cbz" for url in args.URLs]
        case (urls, filename) if len(urls) > 1:
            parser.exit(message="Specifying output with multiple URLs is not supported\n")
        case (_, filename):
            output = filename

    if not args.directory.exists():
        args.directory.mkdir()
    if not args.directory.is_dir():
        parser.exit(status=1, message=f"{args.directory} is not a directory")

    for url, filename in zip(args.URLs, output):
        archive = Archive(filename, find_images(url))
        archive.save(args.directory)


if __name__ == "__main__":
    main()
